---
layout: post
title: TSM
subtitle: Temporal Shift Module for Efficient Video Understanding
categories: paperReading
tags: [paper, cv]
---
今天分享的文章是一篇发表在 ICCV2019 上的、来自于MIT的工作。文章比较新颖的提出通过让模型在 Temporal dimension 上进行移动来达到使信息在时间维度交互的目的，并且在较低FLOPS下得到了十分优异的 Video Action Recognition 结果。



# **Abstract**



在当时，视频的相关 CV 工作的目的是平衡精确度和计算消耗，传统的 2D CNN 虽然计算开销小但是并不能捕捉到视频帧之间的时间关系，而其升级版 3D CNN 虽然能很好的处理时间信息，但是因为多了一个维度使得参数量爆炸，使其很难更进一步发展。



作者因此提出了一种兼具高性能和高精确度的方法，TSM。它的核心思想是`shift part of the channels along the temporal dimension`，因此可以插入到任何 2D CNN 模型中，并在当时取得了 something-something 第一的成绩。



## **Related Work**



Video 相比于 image 多了一个时间维度，以前有做法是将视频看作一系列图像（帧）的堆叠，用 2D CNN 分别单独处理这些图像以试图捕捉视频的整体信息，不过这样做的效果并不好（比如用 resnet），大概原因就是视频中的帧是具有时序信息的，而单独处理每一张图像并不能获取这种时序信息，因此人们就像是否可以用 3D CNN 来处理视频，实践也证明这样是可行的（C3D, I3D, GST），不过因为多了一个维度使得参数量爆炸。



\---



## **参数量计算**



下面会算一下两者的模型复杂度：

***2D CNN*** 很好计算，首先算一个 pixel ，即 ![Snipaste_2021-02-06_12-15-40.png](https://i.loli.net/2021/02/06/qa2u7UeKPyV1iTN.png)

其中分为![Snipaste_2021-02-06_12-17-15.png](https://i.loli.net/2021/02/06/xCqZ2Eubkh5GO6F.png)

次乘法运算和

![Snipaste_2021-02-06_12-17-22.png](https://i.loli.net/2021/02/06/OK2phlHS3xaj7ny.png)次加法运算，只要理解卷积的具体操作的话，理解这个公式并不难。



之后就是乘以整个 feature map 即可。



![1.png](https://i.loli.net/2021/02/06/hXCrS3oflqYy7B1.png)



***3D CNN**则照猫画老虎，因为 feature map 和卷积核各多出一个维度，因此模型复杂度则是 2D CNN 的 K*T 倍。

\---

因为参数量的增加导致 3D CNN `computationally heavy, making the deployment difficult`，因此后来的一些比较新颖的方法都是在 2D CNN 的基础上寻求对时间维度的融合，从而对视频进行训练，比如使用 2D CNN + posthoc fusion 的方法，也有使用 LSTM 的一些模型。



TSM 便是这样的一个模型，他突发奇想地将一个 feature map 沿着 Channel 将时间维度信息进行交换，以此达到使 2D CNN 获取时间维度信息的目的。



![Snipaste_2021-02-06_15-41-15.png](https://i.loli.net/2021/02/06/bkmD7Oxd54fg6zC.png)



# **TSM**

TSM 的核心思想是通道的 shift，而这个 shift 是基本不消耗任何计算资源的（不过比较占内存），因此 TSM 就可以达到作者所说的`low cost as 2D CNN and high efficiency as 3D CNN`。



目前遇见的比较多的就是将 TSM 模块插入到 ResNet 中（当然原作者也是这么用的），简单来讲就是先将输入的一部分进行 shift 操作，再进行常规的卷积操作。

## **Code**

```python
out[:, :-1, :fold] = x[:, 1:, :fold] 
out[:, 1:, fold: 2 * fold] = x[:, :-1, fold: 2 * fold]  
out[:, :, 2 * fold:] = x[:, :, 2 * fold:]
```

## **Result**

不得不说这个 TSM 真的很厉害，计算开销小不说，模型准确度还很厉害。但是后来实验室老板给的模型中加入 TSM 导致显存比较紧张，不过加入后的准确度提升也是很显著的，有个7~8个点。